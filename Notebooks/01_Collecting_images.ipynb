{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a35ff8a",
   "metadata": {},
   "source": [
    "# Purpose of This Notebook  \n",
    "1. We will come up with the name of our hand poses we want detected.\n",
    "1. Take pictures to train our model found in our `02_Training_The_model` notebook.\n",
    "1. Take pictures to test our model on different images not found in step 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a663b6f9",
   "metadata": {},
   "source": [
    "## Table Of Content\n",
    "\n",
    "1. [Imports](#imports)\n",
    "1. [Preparing to Take the Images](#prep)\n",
    "1. [Taking the Pictures for Training](#ready)\n",
    "1. [Taking Validation Pictures](#val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22db0d86",
   "metadata": {},
   "source": [
    "## Imports<span id='imports'>\n",
    "---\n",
    "`mediapipe`: What will be drawing our hands for easier recognition by models  \n",
    "`uuid`: Used to create unique id labels for all of our images  \n",
    "`time`: To set a timer for how long we will take pictures for  \n",
    "`cv2`: OpenCv is what's used to access the webcam   \n",
    "`os`: used to add images to the folders we will make"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e0d804f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "import uuid\n",
    "import time\n",
    "import cv2 \n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1294b0c",
   "metadata": {},
   "source": [
    "<span id='prep'></span>\n",
    "## Preparing for the Loop\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dfd5e79",
   "metadata": {},
   "source": [
    "#### Create Labels for each hand pose, and where we want to save the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef70c590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Hand poses we want to track\n",
    "labels = ['play_pause', 'forward', 'rewind', 'volume_up', 'volume_down', 'screenshot']\n",
    "\n",
    "# path to what folder it will be saved in\n",
    "image_path = '../imgs/collected/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42e1699",
   "metadata": {},
   "source": [
    "**The `collected` folder should start off empty. Folders named after the labels will be created automatically**\n",
    "<img src='./notebook_imgs/collected_folder.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224950fd",
   "metadata": {},
   "source": [
    "### Instantiate MediaPipe to draw the hands.   \n",
    "<img src = https://google.github.io/mediapipe/images/mobile/hand_landmarks.png width=\"650\">  \n",
    "\n",
    "> Will look similar to this but without the numbers on there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30c5af70",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "hands = mp_hands.Hands(\n",
    "    max_num_hands=1,\n",
    "    min_detection_confidence=0.7, # need a 70% confidence of hands to show up\n",
    "    min_tracking_confidence=0.7) # 70% confidence needed to keep tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fb85a0",
   "metadata": {},
   "source": [
    "<span id = 'ready'></span>\n",
    "## Put everything together in a `While Loop` to take all the pictures\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4b73272",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A subdirectory or file .\\imgs\\collected\\play_pause already exists.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting images for play_pause\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A subdirectory or file .\\imgs\\collected\\forward already exists.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting images for forward\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A subdirectory or file .\\imgs\\collected\\rewind already exists.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting images for rewind\n",
      "Collecting images for volume_up\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A subdirectory or file .\\imgs\\collected\\volume_up already exists.\n",
      "A subdirectory or file .\\imgs\\collected\\volume_down already exists.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting images for volume_down\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A subdirectory or file .\\imgs\\collected\\screenshot already exists.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting images for screenshot\n"
     ]
    }
   ],
   "source": [
    "# because sleep is set for 1 sec, should get AROUND same number of pictures as we set this for\n",
    "secs_for_action = 150\n",
    "\n",
    "# instantiate openCV\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# open up my webcam \n",
    "while cap.isOpened():\n",
    "    for idx, label in enumerate(labels):\n",
    "        try:\n",
    "            !mkdir {'..\\imgs\\collected\\\\'+label}\n",
    "        except:\n",
    "            pass\n",
    "        print(f'Collecting images for {label}')\n",
    "        \n",
    "        ret, img = cap.read()\n",
    "        \n",
    "        # tell us what action we're going to be a taking a picture for.\n",
    "        cv2.putText(img, f'Waiting for collecting {label.upper()} action...', org=(10, 30), fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=1, color=(255, 255, 255), thickness=2)\n",
    "        cv2.imshow('Collecting Images', img)\n",
    "        cv2.waitKey(3000)\n",
    "        \n",
    "        # go for as long as we set to take pictures for\n",
    "        start_time = time.time()\n",
    "        while time.time() - start_time < secs_for_action:\n",
    "            ret, img = cap.read()\n",
    "            \n",
    "            # Detections\n",
    "            image = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) # convert image from BGR to RGB to work with mediapipe\n",
    "            image = cv2.flip(image, 1) # flip on horizontal\n",
    "            image.flags.writeable = False    # set flag to False\n",
    "            results = hands.process(image)   # actually makes the detections\n",
    "            image.flags.writeable = True     # set flag back to True\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)  # set color back to BRG\n",
    "            \n",
    "            # Drawing landmarks to the images\n",
    "            if results.multi_hand_landmarks:\n",
    "                for num, hand in enumerate(results.multi_hand_landmarks):\n",
    "                    mp_drawing.draw_landmarks(image, hand, mp_hands.HAND_CONNECTIONS,\n",
    "                                             mp_drawing.DrawingSpec(color=(51, 51, 255), thickness = 2, circle_radius=2),\n",
    "                                             mp_drawing.DrawingSpec(color=(0, 0, 0), thickness = 2, circle_radius=2))\n",
    "\n",
    "                    \n",
    "            \n",
    "            image_name = os.path.join(image_path, label, label+'.'+f'{str(uuid.uuid1())}.jpg')\n",
    "            cv2.imwrite(image_name, image)\n",
    "            cv2.imshow('Collecting Images', image)\n",
    "            \n",
    "            time.sleep(1)\n",
    "            \n",
    "            # press q to break out\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "        \n",
    "        # once we do all 6 labels, lets break out\n",
    "        if idx == (len(labels) - 1):\n",
    "            cap.release()\n",
    "            cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5085dcc",
   "metadata": {},
   "source": [
    "<span id = 'val'></span>\n",
    "## Getting validation images to test our finished model on new unseen images\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3cf21e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = '../imgs/collected/test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bffa963b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting images for picture_1\n",
      "Collecting images for picture_2\n",
      "Collecting images for picture_3\n",
      "Collecting images for picture_4\n",
      "Collecting images for picture_5\n",
      "Collecting images for picture_6\n"
     ]
    }
   ],
   "source": [
    "# because sleep is set for 1 sec, should get AROUND same number of pictures as we set this for\n",
    "secs_for_action = 3\n",
    "\n",
    "# instantiate openCV\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# open up my webcam \n",
    "while cap.isOpened():\n",
    "    for idx, label in enumerate(labels):\n",
    "        print(f'Collecting images for {label}')\n",
    "        \n",
    "        ret, img = cap.read()\n",
    "        \n",
    "        # tell us what action we're going to be a taking a picture for.\n",
    "        cv2.putText(img, f'Waiting for collecting {label.upper()} action...', org=(10, 30), fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=1, color=(255, 255, 255), thickness=2)\n",
    "        cv2.imshow('Collecting Images', img)\n",
    "        cv2.waitKey(3000)\n",
    "        \n",
    "        # go for as long as we set to take pictures for\n",
    "        start_time = time.time()\n",
    "        while time.time() - start_time < secs_for_action:\n",
    "            ret, img = cap.read()\n",
    "            \n",
    "            # Detections\n",
    "            image = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) # convert image from BGR to RGB to work with mediapipe\n",
    "            image = cv2.flip(image, 1) # flip on horizontal\n",
    "            image.flags.writeable = False    # set flag to False\n",
    "            results = hands.process(image)   # actually makes the detections\n",
    "            image.flags.writeable = True     # set flag back to True\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)  # set color back to BRG\n",
    "            \n",
    "            # Drawing landmarks to the images\n",
    "            if results.multi_hand_landmarks:\n",
    "                for num, hand in enumerate(results.multi_hand_landmarks):\n",
    "                    mp_drawing.draw_landmarks(image, hand, mp_hands.HAND_CONNECTIONS,\n",
    "                                             mp_drawing.DrawingSpec(color=(51, 51, 255), thickness = 2, circle_radius=2),\n",
    "                                             mp_drawing.DrawingSpec(color=(0, 0, 0), thickness = 2, circle_radius=2))\n",
    "\n",
    "                    \n",
    "            \n",
    "            image_name = os.path.join(image_path, label+'.'+f'{str(uuid.uuid1())}.jpg')\n",
    "            cv2.imwrite(image_name, image)\n",
    "            cv2.imshow('Collecting Images', image)\n",
    "            \n",
    "            time.sleep(1)\n",
    "            \n",
    "            # press q to cancel \n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "        \n",
    "        # once we do all 6 labels, lets break out\n",
    "        if idx == (len(labels) - 1):\n",
    "            cap.release()\n",
    "            cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
