{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e0d804f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "import uuid\n",
    "from IPython.display import clear_output\n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9cbb14c",
   "metadata": {},
   "source": [
    "\n",
    "**First attempt at trying to store pictures for images**\n",
    "```python\n",
    "labels = ['play_pause', 'forward', 'rewind', 'volume_up', 'volume_down', 'screenshot']\n",
    "num_imgs = 100\n",
    "\n",
    "image_path = './imgs/collected/'\n",
    "\n",
    "# render all the lankmarks on the hand\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# The hands model is the pretrained model/library\n",
    "mp_hands = mp.solutions.hands\n",
    "```\n",
    "---\n",
    "\n",
    "```python\n",
    "for label in labels:\n",
    "     # getting in all the gestuers in collected images as label\n",
    "    !mkdir {'.\\imgs\\collected\\\\'+label}\n",
    "    cap = cv2.VideoCapture(0) # set up webcam to cap\n",
    "    print(f'Collecting images for {label}')  # say what picture we need to be posing for\n",
    "    time.sleep(5) # give 5 seconds between each picture so we can readjust oursevles\n",
    "\n",
    "    for imgnum in range(num_imgs):\n",
    "        clear_output(wait=True)\n",
    "        print(f'label: {label}     Picture{imgnum}')\n",
    "\n",
    "        with mp_hands.Hands(min_detection_confidence=0.7, min_tracking_confidence=0.5) as hands:\n",
    "            ret, frame = cap.read()\n",
    "\n",
    "            # Detections\n",
    "            image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB) # convert image from BGR to RGB to work with mediapipe\n",
    "            image = cv2.flip(image, 1) # flip on horizontal\n",
    "            image.flags.writeable = False    # set flag to False\n",
    "            results = hands.process(image)   # actually makes the detections\n",
    "            image.flags.writeable = True     # set flag back to True\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)  # set color back to BGR\n",
    "\n",
    "            # Drawing landmarks to the images\n",
    "            if results.multi_hand_landmarks:\n",
    "                for num, hand in enumerate(results.multi_hand_landmarks):\n",
    "                    mp_drawing.draw_landmarks(image, hand, mp_hands.HAND_CONNECTIONS,\n",
    "                                             mp_drawing.DrawingSpec(color=(51, 51, 255), thickness = 2, circle_radius=2),\n",
    "                                             mp_drawing.DrawingSpec(color=(0, 0, 0), thickness = 2, circle_radius=2))\n",
    "\n",
    "        # name of frame will say 'hand tracking' and show image\n",
    "        cv2.imshow('Hand Tracking', image)\n",
    "        \n",
    "        # Where do I want to save it to?\n",
    "        image_name = os.path.join(image_path, label, label+'.'+f'{str(uuid.uuid1())}.jpg')\n",
    "        cv2.imwrite(image_name, image)\n",
    "        \n",
    "        # take 2 seconds before the next image\n",
    "        time.sleep(1.5)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release() \n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef70c590",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['play_pause', 'forward', 'rewind', 'volume_up', 'volume_down', 'screenshot']\n",
    "image_path = './imgs/collected/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "30c5af70",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "hands = mp_hands.Hands(\n",
    "    max_num_hands=1,\n",
    "    min_detection_confidence=0.7, # need a 70% confidence of hands to show up\n",
    "    min_tracking_confidence=0.7) # 70% confidence needed to keep tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d4b73272",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A subdirectory or file .\\imgs\\collected\\play_pause already exists.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting images for play_pause\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A subdirectory or file .\\imgs\\collected\\forward already exists.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting images for forward\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A subdirectory or file .\\imgs\\collected\\rewind already exists.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting images for rewind\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A subdirectory or file .\\imgs\\collected\\volume_up already exists.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting images for volume_up\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A subdirectory or file .\\imgs\\collected\\volume_down already exists.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting images for volume_down\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A subdirectory or file .\\imgs\\collected\\screenshot already exists.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting images for screenshot\n"
     ]
    }
   ],
   "source": [
    "# because sleep is set for 1 sec, should get AROUND same number of pictures as we set this for\n",
    "secs_for_action = 15\n",
    "\n",
    "# instantiate openCV\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# open up my webcam \n",
    "while cap.isOpened():\n",
    "    for idx, label in enumerate(labels):\n",
    "        if not os.path.exists(path): # make a folder to save pictures to\n",
    "            !mkdir {'.\\imgs\\collected\\\\'+label}\n",
    "        print(f'Collecting images for {label}')\n",
    "        \n",
    "        ret, img = cap.read()\n",
    "        \n",
    "        # tell us what action we're going to be a taking a picture for.\n",
    "        cv2.putText(img, f'Waiting for collecting {label.upper()} action...', org=(10, 30), fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=1, color=(255, 255, 255), thickness=2)\n",
    "        cv2.imshow('Collecting Images', img)\n",
    "        cv2.waitKey(3000)\n",
    "        \n",
    "        # go for as long as we set to take pictures for\n",
    "        start_time = time.time()\n",
    "        while time.time() - start_time < secs_for_action:\n",
    "            ret, img = cap.read()\n",
    "            \n",
    "            # Detections\n",
    "            image = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) # convert image from BGR to RGB to work with mediapipe\n",
    "            image = cv2.flip(image, 1) # flip on horizontal\n",
    "            image.flags.writeable = False    # set flag to False\n",
    "            results = hands.process(image)   # actually makes the detections\n",
    "            image.flags.writeable = True     # set flag back to True\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)  # set color back to RGB\n",
    "            \n",
    "            # Drawing landmarks to the images\n",
    "            if results.multi_hand_landmarks:\n",
    "                for num, hand in enumerate(results.multi_hand_landmarks):\n",
    "                    mp_drawing.draw_landmarks(image, hand, mp_hands.HAND_CONNECTIONS,\n",
    "                                             mp_drawing.DrawingSpec(color=(51, 51, 255), thickness = 2, circle_radius=2),\n",
    "                                             mp_drawing.DrawingSpec(color=(0, 0, 0), thickness = 2, circle_radius=2))\n",
    "\n",
    "                    \n",
    "            \n",
    "            image_name = os.path.join(image_path, label, label+'.'+f'{str(uuid.uuid1())}.jpg')\n",
    "            cv2.imwrite(image_name, image)\n",
    "            cv2.imshow('Collecting Images', image)\n",
    "            \n",
    "            time.sleep(1)\n",
    "            \n",
    "            # press q to cancel \n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "        \n",
    "        # once we do all 6 labels, lets break out\n",
    "        if idx == (len(labels) - 1):\n",
    "            cap.release()\n",
    "            cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "44906b28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10b2294",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
